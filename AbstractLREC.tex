\documentclass[a4paper,10pt]{article}
%%%% FROM TEMPLATE %%%%
\usepackage{lrec}
\usepackage{multibib}
\newcites{languageresource}{Language Resources}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{soul}
% for eps graphics
\usepackage{epstopdf}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{xstring}
\newcommand{\secref}[1]{\StrSubstitute{\getrefnumber{#1}}{.}{ }}

%%%% OUR DEFS
\usepackage{color}
\newcommand{\TODO}[1]{\begingroup\color{red}#1\endgroup}
\newcommand{\PFS}[1]{\begingroup\color{blue}#1\endgroup}

\title{Does a Phylogeny of Topics Recapitulate the History of Ideas and 
  Institutions? \\
  A Computational Abuse of the Daiz{\=o}ky{\=o}}

\name{\TODO{in no particular Order:} 
Nancy Retzlaff$^1$, Andreas Niekler$^1$, ..., Christoph Kleine$^3$,
Peter F. Stadler$^{1,2,4}$}

\address{MPI Mathematics in the Science, 
         Universit{\"a}t Leipzig, 
         The Santa Fe Institute\\
         Address1, Address2, Address3\\
         \{nancy,studla\}@bioinf.uni-leipzig.de, 
         eisioriginal@gmail.com,
         c.kleine@uni-leipzig.de@bioinf.uni-leipzig.de\\
} 
\date{} 


\abstract{Computational workflows have been devised in a variety of
  research areas in the the humanities, in particular linguistics and
  historical sciences, to make use of the rapidly increasing amount of data
  that have become available in machine-readable form. Here we use the
  \textit{SAT Daiz{\=o}ky{\=o} Text Database}, a digitalized collection of
  2500 years of Buddhist canonical texts, to ask whether historical
  relationships are reflected in the texts in such a way that they can be
  reconstructed using methods adapted from phylogenetics. More
  specifically, we ask whether the presence and abundance high level
  concepts in the writings of Buddhist \TODO{schools} behave akin to
  characters in biological evolution and thus make it possible to infer the
  history of these \TODO{schools} from this type of data alone.
  \TODO{resource aspect} 
% Each article must include an abstract of 150 to 200 words in Times New Roman
% 9 with interlinear spacing of 10 pt. The heading Abstract should be
% centred, font Times New Roman 10 bold. This short abstract will also be used
% for producing the Booklet of Abstracts (PDF) containing the abstracts of all
% papers presented at the Conference. 
\\ 
\newline \Keywords{keyword1, keyword2,
keyword3} }

\begin{document}
\maketitleabstract

\section{Introduction}


Computational approaches have in recent years attempted to reproduce
workflows in the humanities with the aim to leverage to power of
increasingly large amount of data. The most prolific area of application is
historical linguistics, where quantitative methods have had a long
tradition in the field. \TODO{[oder sowas, Nancy, add a couple of
  refs]}. Other types of question in historical sciences also appear to be
amenable to quantitative computational investigations. In
\cite{Laubichler:13}, for the authors advocate a computational big data
approach to the history of sciences. \cite{Rockmore:16} recently
investigated the reuse of ideal in national constitutions at this level. In
the present study we ask whether historical relationships are reflected in
and can be reconstructed using methods adapted from phylogenetics. More
specifically, we ask whether the presence and abundance high level concepts
in the writings of Buddhist \TODO{schools} behave akin to characters in
biological evolution and thus make it possible to infer the history of
these \TODO{schools} from this type of data alone.

  The \textit{SAT Daiz{\=o}ky{\=o} Text Database} \cite{***} is a
  digitalized collection of 2500 years of Buddhist canonical texts. We
  chose this corpus because it concentrate on a limited number of
  relatively clearly defined topics, the texts are dated, and the history
  and relationships of the Buddhist schools that produced them has been
  extensively investigated. It therefore is ideally suited for a
  chronological analysis and computational results can be compared directly
  to established knowledge. 

  The topical structure of the Daiz{\=o}ky{\=o} is investigated using topic
  modelling \cite{Blei12}, a machine learning technique that aims at
  discovering abstract ``topics'' that occur in a collection of documents
  defined in terms of the overrepresented appearance of certain subsets of
  words. In the process, we create a unique resource. First, we need to
  annotate single words, word types and a parse tree in order to identify
  topics and important textual properties. Second, topics are annotated in
  the texts.  In particular word segmentation and POS-tagging task is not
  straightforward since the text source is not standard Chinese. Since
  available tools and models for the automatic annotation of Chinese text
  resources are conditioned to standard modern chinese, we had to create
  new separation and tagging models based on comparable annotated resources
  \cite{Lee14}.  We will contribute the processed corpus as a resource for
  future research on original texts reflecting different buddhist
  \TODO{schools}.

  \textbf{Outline of the computational workflow.} The corpus was acquired
  from the web presence by a web scraper. The content is semi-structured by
  references to the source and the sentence number for each line of
  text. We retained this structure for our final corpus and created a
  source format that links every line of text to its unique identifier
  drawn from the original web source. We defined one scraped web page as a
  single document for the modelling process since this also reflects the
  text structure of the original sources.
    
  The main tools for token separation and POS-tagging of the sources where
  the Stanford Word Segmenter and the Stanford POS-Tagger. Both
  distributions contain pre-trained models Chinese text processing. The
  performance of these models, however, proved unsatisfactory for the
  Daiz{\=o}ky{\=o} corpus. As a consequence we had to retrain the tools
  with an comparable annotated text source conforming to the properties,
  word forms, and \TODO{systectic} features of our target text source.  We
  identified \cite{Lee:12,Wong:16} as text sources in processable form that
  were well suited for retrain our the models for POS-tagging and 
  word separation. The trained models are included with the
  processed version of the \textit{SAT Daiz{\=o}ky{\=o} Text Database},
  which we published \TODO{URL?}.  

  We constructed topic models for the processed corpus using the well
  understood LDA approach \cite{Blei03,GriffithStyvers05}.

%%%  ENDE DER AUSBAUSTRECKE 

We considered multiple quality ensuring techniques in
order to infer an optimal model. Those steps include the assessment of the
topic interpretability and the topic reliability. Both are part of a
transparent and reproducible methodology setup in topic model based content
research.  In detail the interpretability can be asses by two
measures. With the coherence measure [cohen] we can determine the
specificity of the topics in terms of uniqueness of the topic distributions
for each topic. With the word intrusion test [Wang] we implement a human
judgment on the topic quality to the model selection process. Both measures
deliver a comparable quality assessment w.r.t. different topic
solutions. With those measures we do not only rely on measures as
perplexity, likelihood or human judgment in order to select a good topic
solution but also on quantities which asses the topic solution with a novel
measures on the semantic interpretability. Reproducibility is also an issue
when applying topic models to text. Existing studies show that in repeated
runs of the LDA inference on the same dataset reproduce only 65 - 80\% of
the topic solutions throughout all runs [Niekler12, Koltsov14]. For content
research which strongly relies on the interpretation of the topics this is
unsatisfactory and topic selection criterias are hard to explain in a
transparent and reproducible manner. Instead we applies techniques which
raise the topic stability throughout different runs of the model inference,
known as regularization. One very promising approach to influence the
initialization of the inference. Normally, we initialize the topic
assignments beforehand randomly. On the other hand we could seed the random
initialization and hopefully find a similar topic solution throughout
different runs. However, the best solution so far is the initialization of
the topic assignments with a prior semantic clustering of the word
association that can be found in the text [Lancichinetti15]. It can be
shown the the topic reproducibility is raised by 15\% without losing
interpretability. We tested several topic solutions and assessed the
qual√∂ity measures. The results can be found in table 1. It shows that the
optimal solution is XXX which is also confirmed by the word intrusion tests
and quality checks carried out by domain experts.





  Our main tools for the assessment of the topic structure is topic
  modelling .  We will apply the well understood LDA Model to
  the ressources. The resulting topical structure can then be used to
  reveal the topic preference of different times and \TODO{schools} encoded
  in the text.

  \TODO{(the paragraph above is just over 200 words, so 2000 words is about
    4 pages or so, hence are allowed a bit of detail!)}







Quality CHECKS Prof. Kleine

Through this methodology we developed a sound and robust topic solution which can in turn
be used to clarify out research hypothesis. In this step of our research we can now name
the topics for later reference. We can decide between different approaches. On one hand 
we could use term ordering techniques for topic modelling to sort the topic via 
probability, frequency, or specificity (similar as tf/idf but for topics). This leads to 
interpretable word lists which could be used as unique identifiers for the topics. On
the other hand we could augment the description with a detailed commentation on the 
semantic properties. Such a detailed description ensures the later understanding for 
interpretation decisions. The result is documented in figure 1 where we present 3 
translated samples from our text source.

- description of technicalities:
  * corpus
  * preprocessing: crawl data and segmentation of words
  * extraction of features through topic modelling
  * determination of different buddhist "schools" (technical term here please)
  * naming the actual topics (technical term here as well and why it is so hard to do it)
  * assessment of the quantity of phylogenetic signal
  * discrimination of volatile (rapidly changing) topics versus persistent topic 
  (mostly staying the same) 


Now we are in a position to quantify, for each school, the emphasis given a particular 
topic. 


In the simplest case, we compute the relative fraction p(S,T) of the texts from schools S 
that pertain to topic T. Since some topics are inherently more prevalent than others, we 
rather use the corresponding log-likelihood L(S,T) = log p(S,T)/p(T). Each school is thus
represented by a vector of topic importances that can be used to evaluate differences 
between schools. The determine p(S,T) and p(T) utilizing the rank-1 metric. In detail we 
count for every pager, e.g. document, the most probably topic and aggregate the counts 
for all documents w.r.t the school S and topic S. 


We intend to explore both distance based methods and character-based methods commonly 
used in phylogenetics. Simple distance measures that can be expected to behave approximately
additively are the sum over the absolute values of differences of topic importance or a 
thresholded variant thereof. Such distance measures also have the added value that the 
tree-like structure of the data can be assessed a priori, i.e., without having to construct 
a phylogenetic tree \cite{Misof:14}. Thresholding the values of L(S,T) themselves, on the other 
hand, converts the data into discrete characters corresponding to the topics, with 
``overrepresented'' and ``underrepresented''  as binary states. In this form, the data can 
analyzed with maximum parsimony methods. In principle, they are also amenable to maximum 
likelihood methods; however, at this point it seems difficult to argue for specific 
probabilistic transition models (but see \cite{Hruschka:15} for a fully probabilistic model in 
the context of natural language evolution).



\TODO{- are there topics distinguishable due to geography or history?}

\TODO{- checking their consistency to insights from history or religious findings, and hence validating the hypothesis stated above.}

\subsubsection{When Citing Language Resources}

When citing language resources, we recommend to proceed in the same way to
bibliographical references, except that, in order to make them appear in
a separate section, you need to use the \texttt{\\citelanguageresource} tag.
Thus, a language resource should be cited as \citelanguageresource{speecon}.



\section{Bibliographical References}
\label{main:ref}

\bibliographystyle{lrec}
\bibliography{AbstractLREC}


\section{Language Resource References}
\label{lr:ref}
\bibliographystylelanguageresource{lrec}
\bibliographylanguageresource{xample}


\end{document}
