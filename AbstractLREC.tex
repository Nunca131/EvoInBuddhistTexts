\documentclass[a4paper,10pt]{article}
%%%% FROM TEMPLATE %%%%
\usepackage{lrec}
\usepackage{multibib}
\newcites{languageresource}{Language Resources}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{soul}
% for eps graphics
\usepackage{epstopdf}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{xstring}
\newcommand{\secref}[1]{\StrSubstitute{\getrefnumber{#1}}{.}{ }}

%%%% OUR DEFS
\usepackage{xcolor}
\newcommand{\TODO}[1]{\begingroup\color{red}#1\endgroup}
\newcommand{\PFS}[1]{\begingroup\color{blue}#1\endgroup}
\newcommand{\NR}[1]{\begingroup\color{orange}#1\endgroup}

\title{Does a Phylogeny of Topics Recapitulate the History of Ideas and 
  Institutions? \\
  A Computational Abuse of the Daiz{\=o}ky{\=o}}

\name{\TODO{in no particular Order:} 
Nancy Retzlaff$^1$, Andreas Niekler$^1$, ..., Christoph Kleine$^3$,
Peter F. Stadler$^{1,2,4}$}

\address{MPI Mathematics in the Science, 
         Universit{\"a}t Leipzig, 
         The Santa Fe Institute\\
         Address1, Address2, Address3\\
         \{nancy,studla\}@bioinf.uni-leipzig.de, 
         eisioriginal@gmail.com,
         c.kleine@uni-leipzig.de\\
} 
\date{} 

% Each article must include an abstract of 150 to 200 words in Times New Roman
% 9 with interlinear spacing of 10 pt. 

\abstract{Computational workflows have been devised in a variety of
  research areas in the the humanities, in particular linguistics and
  historical sciences, to make use of the rapidly increasing amount of data
  that have become available in machine-readable form. Here we use the
  \textit{SAT Daiz{\=o}ky{\=o} Text Database}, a digitalized collection of
  2500 years of Buddhist canonical texts, to ask whether historical
  relationships are reflected in the texts in such a way that they can be
  reconstructed using methods adapted from phylogenetics. More
  specifically, we ask whether the presence and abundance high level
  concepts in the writings of Buddhist \TODO{schools} behave akin to
  characters in biological evolution and thus make it possible to infer
  their relationsships of descent from this type of data alone.
  %
  We use Topic Modelling to describe the contents of documents in an
  unsupervised and unbiased manner. To this end, we first had to train the
  Stanford Word Segmenter and POS-Tagger for use on the Daiz{\=o}ky{\=o},
  which does not conform to available models for Standard Chinese. The
  annotation of single words, word types and a parse tree as well as the
  topic annotation of entire corpus constitute a unique resource that we
  make available as an itermediate result of the project.\\ 
\newline 
\Keywords{Topic Model, Non-Standard Chinese, Phylogenetics, \TODO{?more?}} 
}

\begin{document}
\maketitleabstract

\section{Introduction}


Computational approaches have in recent years attempted to reproduce
workflows in the humanities with the aim to leverage to power of
increasingly large amount of data. The most prolific area of application is
historical linguistics, where quantitative methods have had a long
tradition in the field (for example see 
\cite{levinson_tools_2012,gray_language-tree_2003,croft2008evolutionary}). 
Other types of question in historical sciences also appear to be
amenable to quantitative computational investigations. In
\cite{Laubichler:13}, for the authors advocate a computational big data
approach to the history of sciences. \cite{Rockmore:16} recently
investigated the reuse of ideal in national constitutions at this level. In
the present study we ask whether historical relationships are reflected in
and can be reconstructed using methods adapted from phylogenetics. More
specifically, we ask whether the presence and abundance high level concepts
in the writings of Buddhist \TODO{schools} behave akin to characters in
biological evolution and thus make it possible to infer the history of
these \TODO{schools} from this type of data alone.

The \textit{SAT Daiz{\=o}ky{\=o} Text Database} \citelanguageresource{Daizokyo} is a digitalized
collection of 2500 years of Buddhist canonical texts. We chose this corpus
because it concentrate on a limited number of relatively clearly defined
topics, the texts are dated, and the history and relationships of the
Buddhist schools that produced them has been extensively investigated. It
therefore is ideally suited for a chronological analysis and computational
results can be compared directly to established knowledge.

The topical structure of the Daiz{\=o}ky{\=o} is investigated using topic
modelling \cite{Blei12}, a machine learning technique that aims at
discovering abstract ``topics'' that occur in a collection of documents
defined in terms of the overrepresented appearance of certain subsets of
words. In the process, we create a unique resource. First, we need to
annotate single words, word types and a parse tree in order to identify
topics and important textual properties. Second, topics are annotated in
the texts.  In particular word segmentation and POS-tagging task is not
straightforward since the text source is not Standard Chinese. Since
available tools and models for the automatic annotation of Chinese text
resources are conditioned to \NR{(modern)} Standard Chinese, we had to create new
separation and tagging models based on comparable annotated resources
\cite{Lee14}.  We will contribute the processed corpus as a resource for
future research on original texts reflecting different buddhist
\TODO{schools}.

\TODO{Blei12 = blei2012probabilistic in .bib? and Lee14}

\textbf{Outline of the computational workflow.} \NR{As text ressource we 
used the \textit{SAT Daiz{\=o}ky{\=o} Text Database}. Unfortunately, the data presented on 
\cite{Daizokyo} did not contain any punctuation marks and was, therefore,
unsuited for topic modeling. Hence, we chose \TODO{\cite{DaiCD}} where the 
corpus was represented in XML format. We automatically obtained the plain texts and 
manually reencoded the files for further processing.} The content is semi-structured by
references to the source and the sentence number for each line of text. We
retained this structure for our final corpus and created a source format
that links every line of text to its unique identifier drawn from the
original web source. We defined one scraped web page as a single document
for the modelling process since this also reflects the text structure of
the original sources.
    
  The main tools for token separation and POS-tagging of the sources where
  the Stanford Word Segmenter and the Stanford POS-Tagger. Both
  distributions contain pre-trained models Chinese text processing. The
  performance of these models, however, proved unsatisfactory for the
  Daiz{\=o}ky{\=o} corpus. As a consequence we had to retrain the tools
  with an comparable annotated text source conforming to the properties,
  word forms, and \TODO{systectic} features of our target text source.  We
  identified \cite{Lee:12,Wong:16} as text sources in processable form that
  were well suited for retrain our the models for POS-tagging and 
  word separation. The trained models are included with the
  processed version of the \textit{SAT Daiz{\=o}ky{\=o} Text Database},
  which we published \TODO{URL?}.  

  We constructed topic models for the processed corpus using the well
  understood LDA approach \cite{Blei03,GriffithStyvers05}.
  
  \TODO{Blei03 = blei2003latent or blei2003modeling, in .bib? and GriffithStyvers05
  = griffiths2005integrating in .bib?}

%%%  ENDE DER AUSBAUSTRECKE 

We considered multiple quality ensuring techniques in
order to infer an optimal model. \NR{These} steps include the assessment of the
topic interpretability and the topic reliability. Both are part of a
transparent and reproducible methodology setup in topic model based content
research.  In detail the interpretability can be assessed by two
measures\NR{: (a) w}ith the coherence measure \cite{cohen} we can determine the
specificity of the topics in terms of uniqueness of the topic distributions
for each topic\NR{; (b) w}ith the word intrusion test \cite{Wang} we implement a human
judgment on the topic quality to the model selection process. Both measures
deliver a comparable quality assessment w.r.t. different topic
solutions. With those measures we do not only rely on measures as
perplexity, likelihood, or human judgment in order to select a good topic
solution but also on quantities which assess the topic solution with a novel
measure on the semantic interpretability. Reproducibility is also an issue
when applying topic models to text. Existing studies show that in repeated
runs of the LDA inference on the same dataset reproduce only 65 - 80\% of
the topic solutions throughout all runs \cite{Niekler12,Koltsov14}. For content
research which strongly relies on the interpretation of the topics this is
unsatisfactory and topic selection criterias are hard to explain in a
transparent and reproducible manner. Instead we applied techniques which
raise the topic stability throughout different runs of the model inference,
known as regularization. One  very promising approach is to influence the
initialization of the inference. Normally, we initialize the topic
assignments beforehand randomly \NR{whereas o}n the other hand we could seed the random
initialization and hopefully find a similar topic solution throughout
different runs. However, the best solution so far is the initialization of
the topic assignments with a prior semantic clustering of the word
association that can be found in the text \cite{Lancichinetti15}. It can be
shown the the topic reproducibility is raised by 15\% without losing
interpretability. We tested several topic solutions and assessed the
quality measures. The results can be found in \TODO{Table 1}. It shows that the
optimal solution is \TODO{XXX} which is also confirmed by the word intrusion tests
and quality checks carried out by domain experts.

\TODO{cites: cohen, Wang, Niekler12, Koltsov14, Lancichinetti15}



\TODO{Should following paragraph still be included?} \NR{First part sounds 
redundant. Maybe include second part later as an aim of this approach?}
  [Our main tools for the assessment of the topic structure is topic
  modelling.  We will apply the well understood LDA Model to
  the ressources. The resulting topical structure can then be used to
  reveal the topic preference of different times and \TODO{schools} encoded
  in the text.]







Quality CHECKS Prof. Kleine

Through this methodology we developed a sound and robust topic solution which can in turn
be used to clarify out research hypothesis. In this step of our research we can now name
the topics for later reference. We can decide between different approaches. On one hand 
we could use term ordering techniques for topic modelling to sort the topic via 
probability, frequency, or specificity (similar as tf/idf but for topics). This leads to 
interpretable word lists which could be used as unique identifiers for the topics. On
the other hand we could augment the description with a detailed commentation \NR{commentary?} on the 
semantic properties. Such a detailed description \NR{documentation?} ensures the later understanding of 
interpretation decisions. The result is documented in \TODO{Figure 1} where we present 3 
translated samples from our text source.

- description of technicalities:
\begin{itemize}
 \item corpus
 \item preprocessing: crawl data and segmentation of words
 \item extraction of features through topic modelling
 \item determination of different buddhist "schools" (technical term here please)
 \item naming the actual topics (technical term here as well and why it is so hard to do it)
 \item assessment of the quantity of phylogenetic signal
 \item discrimination of volatile (rapidly changing) topics versus persistent topic 
  (mostly staying the same) 
\end{itemize}


Now we are in a position to quantify, for each school, the emphasis given a particular 
topic. 


In the simplest case, we compute the relative fraction $p(S,T)$ of the texts from schools S 
that pertain to topic $T$. Since some topics are inherently more prevalent than others, we 
rather use the corresponding log-likelihood $L(S,T) = \log p(S,T)/p(T)$. Each \TODO{school} is thus
represented by a vector of topic importances that can be used to evaluate differences 
between \TODO{schools}. The determine $p(S,T)$ and $p(T)$ utilizing the rank-1 metric. In detail we 
count for every pager, e.g. document, the most probably topic and aggregate the counts 
for all documents w.r.t the school $S$ and topic $T$. 


We intend to explore both distance based methods and character-based methods commonly 
used in phylogenetics. Simple distance measures that can be expected to behave approximately
additively are the sum over the absolute values of differences of topic importance or a 
thresholded variant thereof. Such distance measures also have the added value that the 
tree-like structure of the data can be assessed a priori, i.e., without having to construct 
a phylogenetic tree \cite{Misof:14}. Thresholding the values of $L(S,T)$ themselves, on the other 
hand, converts the data into discrete characters corresponding to the topics, with 
``overrepresented'' and ``underrepresented''  as binary states. In this form, the data can 
analyzed with maximum parsimony methods. In principle, they are also amenable to maximum 
likelihood methods; however, at this point it seems difficult to argue for specific 
probabilistic transition models (but see \cite{Hruschka:15} for a fully probabilistic model in 
the context of natural language evolution).



\TODO{- are there topics distinguishable due to geography or history?}

\TODO{- checking their consistency to insights from history or religious findings, and hence validating the hypothesis stated above.}

\subsubsection{When Citing Language Resources}

When citing language resources, we recommend to proceed in the same way to
bibliographical references, except that, in order to make them appear in
a separate section, you need to use the \texttt{\\citelanguageresource} tag.
Thus, a language resource should be cited as \citelanguageresource{speecon}.



\section{Bibliographical References}
\label{main:ref}

\bibliographystyle{lrec}
\bibliography{AbstractLREC}


\section{Language Resource References}
\label{lr:ref}
\TODO{bibitem is "broken", anyone any idea how to fix it?}
\bibliographystylelanguageresource{lrec}
\bibliographylanguageresource{AbstractLREC}

\end{document}
