\documentclass[a4paper,10pt]{article}
%%%% FROM TEMPLATE %%%%
\usepackage{lrec}
\usepackage{multibib}
\newcites{languageresource}{Language Resources}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{soul}
% for eps graphics
\usepackage{epstopdf}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{xstring}
\newcommand{\secref}[1]{\StrSubstitute{\getrefnumber{#1}}{.}{ }}

%%%% OUR DEFS
\usepackage{xcolor}
\newcommand{\TODO}[1]{\begingroup\color{red}#1\endgroup}
\newcommand{\PFS}[1]{\begingroup\color{blue}#1\endgroup}
\newcommand{\NR}[1]{\begingroup\color{orange}#1\endgroup}

\title{Does a Phylogeny of Topics Recapitulate the History of Ideas and 
  Institutions? \\
  A Computational Abuse of the Daiz{\=o}ky{\=o}}

\name{Nancy Retzlaff$^1$, Andreas Niekler$^2$, Gerhard Heyer$^2$, Christoph Kleine$^3$,
Peter F. Stadler$^{1,2,4}$}

\address{$^1$MPI Mathematics in the Science, Inselstra{\ss}e 22, D-04103 Leipzig, Germany,\\
         $^2$Universit{\"a}t Leipzig, Augustusplatz 10, D-04109 Leipzig, Germany, \\
         $^3$Universit{\"a}t Leipzig, Schillerstra{\ss}e 6, D-04109 Leipzig, Germany \\
         $^4$The Santa Fe Institute, 1399 Hyde Park Rd, Santa Fe, NM 87501, USA\\
         \{nancy,studla\}@bioinf.uni-leipzig.de, 
         \{aniekler,heyer\}@informatik.uni-leipzig.de, 
         c.kleine@uni-leipzig.de\\
} 
\date{} 

% Each article must include an abstract of 150 to 200 words in Times New Roman
% 9 with interlinear spacing of 10 pt. 

\abstract{Computational workflows have been devised in a variety of
  research areas in the the humanities, in particular linguistics and
  historical sciences, to make use of the rapidly increasing amount of data
  that have become available in machine-readable form. Here we use the
  \textit{SAT Daiz{\=o}ky{\=o} Text Database}, a digitalized collection of
  2500 years of Buddhist canonical texts, to ask whether historical
  relationships are reflected in the texts in such a way that they can be
  reconstructed using methods adapted from phylogenetics. More
  specifically, we ask whether the presence and abundance high level
  concepts in the writings of Buddhist \TODO{schools} behave akin to
  characters in biological evolution and thus make it possible to infer
  their relationsships of descent from this type of data alone.
  %
  We use Topic Modelling to describe the contents of documents in an
  unsupervised and unbiased manner. To this end, we first had to train the
  Stanford Word Segmenter and POS-Tagger for use on the Daiz{\=o}ky{\=o},
  which does not conform to available models for Standard Chinese. The
  annotation of single words, word types and a parse tree as well as the
  topic annotation of entire corpus constitute a unique resource that we
  make available as an itermediate result of the project.\\ 
\newline 
\Keywords{Topic Model, Non-Standard Chinese, Phylogenetics, \TODO{?more?}} 
}

\begin{document}
\maketitleabstract

\section{Introduction}

Computational approaches have in recent years attempted to reproduce
workflows in the humanities with the aim to leverage to power of
increasingly large amount of data. The most prolific area of application is
historical linguistics, where quantitative methods have had a long
tradition in the field (for example see 
\cite{levinson_tools_2012,gray_language-tree_2003,croft2008evolutionary}). 
Other types of questions in historical sciences also appear to be
amenable to quantitative computational investigations. In
\cite{Laubichler:13}, for the authors advocate a computational big data
approach to the history of sciences. \cite{Rockmore:16} recently
investigated the reuse of ideal in national constitutions at this level. In
the present study we ask whether historical relationships are reflected in
and can be reconstructed using methods adapted from phylogenetics. More
specifically, we ask whether the presence and abundance high level concepts
in the writings of Buddhist \TODO{schools} behave akin to characters in
biological evolution and thus make it possible to infer the history of
these \TODO{schools} from this type of data alone.

The \textit{SAT Daiz{\=o}ky{\=o} Text Database}
\citelanguageresource{Daizokyo} is a digitalized collection of 2500 years
of Buddhist canonical texts. We chose this corpus because it concentrate on
a limited number of relatively clearly defined topics, the texts are dated,
and the history and relationships of the Buddhist schools that produced
them has been extensively investigated. It therefore is ideally suited for
a chronological analysis and computational results can be compared directly
to established knowledge.

The topical structure of the Daiz{\=o}ky{\=o} is investigated using topic
modelling \cite{blei2012probabilistic}, a machine learning technique that
aims at discovering abstract ``topics'' that occur in a collection of
documents defined in terms of the overrepresented appearance of certain
subsets of words. In the process, we create a unique resource. First, we
need to annotate single words, word types and a parse tree in order to
identify topics and important textual properties. Second, topics are
annotated in the texts.  In particular word segmentation and POS-tagging
task is not straightforward since the text source is not Standard
Chinese. Since available tools and models for the automatic annotation of
Chinese text resources are conditioned to \NR{(modern)} Standard Chinese,
we had to create new separation and tagging models based on comparable
annotated resources \cite{Wong:16}.  We will contribute the processed corpus
as a resource for future research on original texts reflecting different
buddhist \TODO{schools}.

\section{Methods and Workflow} 

\paragraph{Data Source.} The \textit{SAT Daiz{\=o}ky{\=o} Text
    Database} \citelanguageresource{Daizokyo} does not contain any
  punctuation marks and therefore was not suitable for as input for topic
  modeling in this form. The presentation of the corpus in XML format
  \TODO{\cite{DaiCD}} therefore was converted to a plain text format.
  
  We manually reencoded the files for further processing.
  \TODO{NANCY, be more specific: what needed to be recoded?} 

  The resulting corpus is semi-structured by references to the source and
  the sentence number for each line of text. We retained this structure for
  our final corpus and created a source format that links every line of
  text to its unique identifier drawn from the original web source. We
  defined one scraped web page as a single document for the modelling
  process since this also reflects the text structure of the original
  sources.
    
\paragraph{Text Annotation.} 
  The main tools for token separation and POS-tagging of the sources where
  the Stanford Word Segmenter and the Stanford POS-Tagger {\cite{manning:2014}. Both distributions contain pre-trained models Chinese
  text processing. The performance of these models, however, proved
  unsatisfactory for the Daiz{\=o}ky{\=o} corpus. As a consequence we had
  to retrain the tools with an comparable annotated text source conforming
  to the properties, word forms, and \TODO{systectic} features of our
  target text source.  We identified \cite{Lee:12,Wong:16} as text sources
  in processable form that were well suited for retrain our the models for
  POS-tagging and word separation. The trained models are included with the
  processed version of the \textit{SAT Daiz{\=o}ky{\=o} Text Database},
  which we published \TODO{URL?}.

\paragraph{Topic Modelling.}
  We constructed topic models for the processed corpus using the well
  understood Latent Dirichlet Allocation (LDA) approach \cite{blei:2012,griffiths:2004}. In our corpus it is a free decision where a document boundary could be set.  For LDA the document is the main context unit and thus, we have to set document boundaries for the algorithm. \TODO{What does on file resp. page in our sources mean -- if we set this as documents how do we justify this -- do they represent paragraphs or chapters?}

We considered multiple quality ensuring techniques in
order to infer an optimal model. \NR{These} steps include the assessment of the
topic interpretability and the topic reliability. Both are part of a
transparent and reproducible methodology setup in topic model based content
research.  In detail the interpretability can be assessed by two
measures\NR{: (a) w}ith the coherence measure \cite{newman:2010} we can determine the
specificity of the topics in terms of uniqueness of the topic distributions
for each topic\NR{; (b) w}ith the word intrusion test \cite{chang:2009} we implement a human
judgment on the topic quality to the model selection process. Both measures
deliver a comparable quality assessment w.r.t. different topic
solutions. With those measures we do not only rely on measures as
perplexity, likelihood, or human judgment in order to select a good topic
solution but also on quantities which assess the topic solution with a novel
measure on the semantic interpretability. Reproducibility is also an issue
when applying topic models to text. Existing studies show that in repeated
runs of the LDA inference on the same dataset reproduce only 65 - 80\% of
the topic solutions throughout all runs \cite{niekler:2012,koltcov:2016}. For content
research which strongly relies on the interpretation of the topics this is
unsatisfactory and topic selection criterias are hard to explain in a
transparent and reproducible manner. Instead we applied so-called
regularization techniques that
raise the topic stability throughout different runs of the model inference. One  very promising approach is to influence the
initialization of the inference. Normally, we initialize the topic
assignments beforehand randomly, \NR{whereas o}n the other hand we could seed the random
initialization and hopefully find a similar topic solution throughout
different runs. However, the best solution so far is the initialization of
the topic assignments with a prior semantic clustering of the word
association that can be found in the text \cite{lancichinetti:2015}. It can be
shown the the topic reproducibility is raised by 15\% without losing
interpretability. We tested several topic solutions and assessed the
quality measures. 

%Should be integrated in the full paper!!!
%The results can be found in \TODO{Table 1}. It shows that the
%optimal solution is \TODO{XXX} which is also confirmed by the word intrusion tests
%and quality checks carried out by domain experts.

\TODO{Should following paragraph still be included?} \NR{First part sounds 
redundant. Maybe include second part later as an aim of this approach?}
  [Our main tools for the assessment of the topic structure is topic
  modelling.  We will apply the well understood LDA Model to
  the ressources. The resulting topical structure can then be used to
  reveal the topic preference of different times and \TODO{schools} encoded
  in the text.]


Quality CHECKS Prof. Kleine

Through this methodology we developed a sound and robust topic solution
which can in turn be used to clarify out research hypothesis.
In this step of our research we can now name
the topics for later reference. We can decide between different approaches. On one hand 
we could use term ordering techniques for topic modelling to sort the topic via 
probability, frequency, or specificity (similar as tf/idf but for topics). This leads to 
interpretable word lists which could be used as unique identifiers for the topics. On
the other hand we could augment the description with a detailed commentation \NR{commentary?} on the 
semantic properties. Such a detailed description \NR{documentation?} ensures the later understanding of 
interpretation decisions. The result is documented in \TODO{Figure 1} where we present 3 
translated samples from our text source.


\paragraph{Assignment of Topics to Documents and Schools.} 

\PFS{Topics are initially assigned to individual documents.} We do this by examining  the document-topic distribution $p(\mathbf{z}|D) (\Theta_D)$ given by the $\Theta$-Parameter of the LDA model for each document $D$. Therein, we could sort the topics by their probability w.r.t. the document $D$. We assign a topic index to each document analogous to the rank-1 metric \cite{evans:2014}. This metric determines a primary topic for each document by assigning  the most probable topic from the distribution $p(\mathbf{z}|D) (\Theta_D)$ as primary topic.  This method is particularly compelling when documents are short. Utilizing this procedure prevents "`Background"'-topics, such as domain specific recurring contexts, to be overrated in the topic statistics. We alter this approach by selecting the 2 most probably topics for each document in order to preserve the  \NR{multi-topic-properties} given by the LDA model. An alternative would be the aggregation of the probability mass for each document but this will lead to skewed statistics due to the "`Background"'-topics which contribute a little amount of probability to each document in the corpus.

The next step is to aggregate of the document-wise topic index in order to
describe topical preferences of individual schools.  In the simplest case,
we compute the relative fraction $p(S,T)$ of documents from schools $S$ for
which topic $T$ in assigned as the primary or secondary topic in the sense defined above.  Since
some topics are inherently more prevalent than others, we rather use the
corresponding log-likelihood $L(S,T) = \log p(S,T)/p(T)$, where $p(T)$ is
the fraction of documents in the entire corpus for which $T$ is
important. This measure quantifies, for each \TODO{school}, the emphasis
given a particular topic.


\section{Phylogenetics on Topic Data} 

Each \TODO{school} is represented by a vector of topic importances that can
be used to evaluate differences between \TODO{schools}.  Thresholding
$L(S,T)$ converts the topic importances into binary vectors that correspond
to the so-called character tables that play a central role in
phylogenetics. Each \TODO{school} (taxon) is the characterized by the
``presence'' (overrepresentation) or ``absence'' of a character (topic).
In this form, the data can analyzed with maximum parsimony methods, a
understood class of computational methods from computational phylogenetics
designed to infer tree models. In principle, they are also amenable to
maximum likelihood methods; however, at this point it seems difficult to
argue for specific probabilistic transition models (but see
\cite{Hruschka:15} for a fully probabilistic model in the context of
natural language evolution). Alternatively, distances between importance
vectors can be computed. There may then be used as input to distance-based
methods of tree reconstruction. Simple distance measures that can be
expected to behave approximately additively are the sum over the absolute
values of differences of topic importance or a thresholded variant
thereof. Such distance measures also have the added value that the
tree-like structure of the data can be assessed a priori, i.e., without
having to construct a phylogenetic tree \cite{Misof:14}.

In most biological applications only taxa that a alive in the present are
observable. Even when applied to paleontological data, only leaves of the
tree are observable, while all interior nodes are only inferred. In the
case of historical records, however, true ancestor may be represented in
the data. In the case of the Daiz{\=o}ky{\=o}, as dense, dated corpus is
available that can be subdivided into time slices that then take the role
of individual taxa. These now may also represent interior nodes of the
tree. Although methods to deal with this type of phylogenetic problem are
not well developed, efficient algorithms for both distance-based and the
character-bases variants of the problem are available \cite{Telles:13} and
have been applied successfully to document data. 


















\TODO{- are there topics distinguishable due to geography or history?}

\TODO{- checking their consistency to insights from history or religious findings, and hence validating the hypothesis stated above.}



\section{Bibliographical References}
\label{main:ref}

\bibliographystyle{lrec}
\bibliography{AbstractLREC}


\section{Language Resource References}
\label{lr:ref}
\TODO{bibitem is "broken", anyone any idea how to fix it?}
\bibliographystylelanguageresource{lrec}
\bibliographylanguageresource{AbstractLREC}

\end{document}
