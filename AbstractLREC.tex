\documentclass[a4paper,10pt]{article}
%%%% FROM TEMPLATE %%%%
\usepackage{lrec}
\usepackage{multibib}
\newcites{languageresource}{Language Resources}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{soul}
% for eps graphics
\usepackage{epstopdf}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{xstring}
\newcommand{\secref}[1]{\StrSubstitute{\getrefnumber{#1}}{.}{ }}

%%%% OUR DEFS
\usepackage{xcolor}
\newcommand{\TODO}[1]{\begingroup\color{red}#1\endgroup}
\newcommand{\PFS}[1]{\begingroup\color{blue}#1\endgroup}
\newcommand{\NR}[1]{\begingroup\color{orange}#1\endgroup}

\title{Does a Phylogeny of Topics Recapitulate the History of Ideas and 
  Institutions? \\
  A Computational Abuse of the Daiz{\=o}ky{\=o}}

\name{Nancy Retzlaff$^1$, Andreas Niekler$^2$, 
  Gerhard Heyer$^2$, Christoph Kleine$^3$,
  Peter F. Stadler$^{1,2,4}$}

\address{$^1$MPI Mathematics in the Science, Inselstra{\ss}e 22, D-04103
  Leipzig
, Germany,\\
         $^2$Universit{\"a}t Leipzig, Augustusplatz 10, D-04109 Leipzig, Germany, \\
         $^3$Universit{\"a}t Leipzig, Schillerstra{\ss}e 6, D-04109 Leipzig, Germany \\
         $^4$The Santa Fe Institute, 1399 Hyde Park Rd, Santa Fe, NM 87501, USA\\
         \{nancy,studla\}@bioinf.uni-leipzig.de, 
         \{aniekler,heyer\}@informatik.uni-leipzig.de, 
         c.kleine@uni-leipzig.de\\
} 
\date{} 

% Each article must include an abstract of 150 to 200 words in Times New Roman
% 9 with interlinear spacing of 10 pt. 

\abstract{Computational workflows have been devised in a variety of
  research areas in the the humanities, in particular linguistics and
  historical sciences, to make use of the rapidly increasing amount of data
  that have become available in machine-readable form. Here we use the
  \textit{Chinese Electronic Tripi{\d{t}}aka Collection}, a digitalized
  collection of 2500 years of Buddhist canonical texts, to ask whether
  historical relationships are reflected in the texts in such a way that
  they can be reconstructed using methods adapted from phylogenetics. More
  specifically, we ask whether the presence and abundance high level
  concepts in the writings of Buddhist schools of thought behave akin to
  characters in biological evolution and thus make it possible to infer
  their relationsships of descent from this type of data alone.
  %
  We use Topic Modelling to describe the contents of documents in an
  unsupervised and unbiased manner. To this end, we first had to train the
  Stanford Word Segmenter and POS-Tagger for use on the \textit{Chinese
    Electronic Tripi{\d{t}}aka Collection}, which does not conform to
  available models for Standard Chinese. The annotation of single words,
  word types and a parse tree as well as the topic annotation of entire
  corpus constitute a unique resource that we
  make available as an itermediate result of the project.\\
  \newline \Keywords{Topic Model, Non-Standard Chinese, Phylogenetics,
    Buddhism} }

\begin{document}
\maketitleabstract

\section{Introduction}

Computational approaches have in recent years attempted to reproduce
workflows in the humanities with the aim to leverage to power of
increasingly large amount of data. The most prolific area of application is
historical linguistics, where quantitative methods have had a long
tradition in the field (for example see 
\cite{levinson_tools_2012,gray_language-tree_2003,croft2008evolutionary}). 
Other types of questions in historical sciences also appear to be
amenable to quantitative computational investigations. In
\cite{Laubichler:13}, for the authors advocate a computational big data
approach to the history of sciences. \cite{Rockmore:16} recently
investigated the reuse of ideal in national constitutions at this level. In
the present study we ask whether historical relationships are reflected in
and can be reconstructed using methods adapted from phylogenetics. More
specifically, we ask whether the presence and abundance high level concepts
in the writings of Buddhist schools of thought behave akin to characters in
biological evolution and thus make it possible to infer the history of
these schools from this type of data alone.

The \textit{Chinese Electronic Tripi{\d{t}}aka Collection}, digitalized by
the Chinese Buddhist Text Association (CBETA) based in Taibei (Taiwan), is
the most comprehensive collection of authoritative Buddhist texts written
in or translated into Chinese over many centuries from roughly in the late
2nd century A.D. in more than 15.000 scrolls (Chinese Buddhist Electronic
Text Association, 2016). It includes various text corpora mostly edited in
the early 20th century for scholarly purposes, the most important being the
\emph{Taish{\=o} shinsh{\=u} daiz{\=o}ky{\=o}}, published in 100 volumes
(of which vols. 1-55 and vol. 85 were digitalized) by Japanese scholars
between 1924 and 1934 \cite{Juniro:24-34}. It therefore is ideally suited
for a chronological analysis and computational results can be compared
directly to established knowledge.



The topical structure of the \textit{Chinese Electronic Tripi{\d{t}}aka
  Collection} \citelanguageresource{CBETA:16} is investigated using topic
modelling \cite{blei2012probabilistic}, a machine learning technique that
aims at discovering abstract ``topics'' that occur in a collection of
documents defined in terms of the overrepresented appearance of certain
subsets of words. In the process, we create a unique resource. First, we
need to annotate single words, word types and a parse tree in order to
identify topics and important textual properties. Second, topics are
annotated in the texts.  In particular word segmentation and POS-tagging
task is not straightforward since the text source is not Standard
Chinese. Since available tools and models for the automatic annotation of
Chinese text resources are conditioned to (modern) Standard Chinese, we had
to create new separation and tagging models based on comparable annotated
resources \citelanguageresource{Wong:16}.  We will contribute the processed
corpus as a resource for future research on original texts reflecting
different buddhist schools.

\section{Methods and Workflow} 

\paragraph{Data Source.} The \textit{Chinese Electronic Tripi{\d{t}}aka
  Collection} \cite{} does not contain any punctuation marks and therefore
was not suitable for as input for topic modeling in this form. The
presentation of the corpus in XML format \citelanguageresource{CBETA:16}
therefore was converted to a plain text format.
  
  We manually reencoded the files for further processing \NR{since the data
  was not uniformly stored in UTF-8 format}.
%   \TODO{NANCY, be more specific: what needed to be recoded?} 

  The resulting corpus is semi-structured by references to the source and
  the sentence number for each line of text. We retained this structure for
  our final corpus and created a source format that links every line of
  text to its unique identifier drawn from the original web source. We
  defined one scraped web page as a single document for the modelling
  process since this also reflects the text structure of the original
  sources.
    
\paragraph{Text Annotation.} 
The main tools for token separation and POS-tagging of the sources where
the Stanford Word Segmenter and the Stanford POS-Tagger
\cite{manning:2014}.  Both distributions contain pre-trained models Chinese
text processing. The performance of these models, however, proved
unsatisfactory for the Daiz{\=o}ky{\=o} corpus. As a consequence we had to
retrain the tools with an comparable annotated text source conforming to
the properties, word forms, and \TODO{systectic} features of our target
text source.  We identified \citelanguageresource{Lee:12,Wong:16} as text
sources in processable form that were well suited for retrain our the
models for POS-tagging and word separation. The trained models are included
with the processed version of the \textit{Chinese Electronic
  Tripi{\d{t}}aka Collection}, which we published \TODO{URL?}.

\paragraph{Topic Modelling.}
  We constructed topic models for the processed corpus using the well
  understood Latent Dirichlet Allocation (LDA) approach 
  \cite{blei:2012,griffiths:2004}. In our corpus it is a free decision where 
  a document boundary could be set.  For LDA the document is the main context 
  unit and thus, we have to set document boundaries for the algorithm. 
  \TODO{What does on file resp. page in our sources mean -- if we set this as 
  documents how do we justify this -- do they represent paragraphs or chapters?}

We considered multiple quality ensuring techniques in order to infer an
optimal model. These steps include the assessment of the topic
interpretability and the topic reliability. Both are part of a transparent
and reproducible methodology setup in topic model based content research.
In detail the interpretability can be assessed by two measures: (a) the
coherence measure \cite{newman:2010} determines the specificity of the
topics in terms of uniqueness of the topic distributions for each topic;
(b) the word intrusion test \cite{chang:2009} employs a human judgment on
the topic quality to guide the model selection process. Both measures
deliver a comparable quality assessment w.r.t.\ different topic
solutions. With these measures we do not only rely on measures such as
perplexity, likelihood, or human judgment in order to select a good topic
solution but also on quantities that assess the topic solution with a novel
measure on the semantic interpretability. Reproducibility is also an issue
when applying topic models to text. Existing studies show that LDA
inference run repeatedly on the same dataset reproduces only 65\% to 80\%
of the topic solutions across all runs \cite{niekler:2012,koltcov:2016}.
For content research, which strongly relies on the interpretation of the
topics, this is of course unsatisfactory. Furthermore, topic selection
criteria are hard to explain in a transparent and reproducible manner. As
an alternative we therefore applied so-called regularization techniques
that raise the topic stability throughout different runs of the model
inference. One very promising approach is to influence the initialization
of the inference. Normally, we initialize the topic assignments beforehand
randomly, whereas on the other hand we could seed the random initialization
and hopefully find a similar topic solution throughout different
runs. However, the best solution so far is the initialization of the topic
assignments with a prior semantic clustering of the word association that
can be found in the text \cite{lancichinetti:2015}. It can be shown the the
topic reproducibility is raised by 15\% without losing interpretability. We
tested several topic solutions and assessed the quality measures.

%Should be integrated in the full paper!!!
%The results can be found in \TODO{Table 1}. It shows that the
%optimal solution is \TODO{XXX} which is also confirmed by the word intrusion tests
%and quality checks carried out by domain experts.

\TODO{Quality CHECKS Prof. Kleine} 

\PFS{In summary, we have developed a sound and robust topic solution.
  Computationally identified topics need to be named, i.e., associated with
  a interpretable content for later reference.}  We can decide between
different approaches. On one hand we could use term ordering techniques for
topic modelling to sort the topic via probability, frequency, or
specificity (similar as tf/idf, but for topics). This leads to
interpretable word lists which could be used as unique identifiers for the
topics. Alternatively, we could augment the topic description with a
detailed commentation on the semantic properties. \PFS{Such a detailed
  description also documents the reasons of the decisions taken in deciding
  on the topic name.} The result is documented in Fig.~\ref{fig:topixampl}
where we present 3 translated samples from our text source.

\begin{figure}
  \begin{center} 
    \TODO{Three cool topics!} 
  \end{center}
  \caption{Something very intelligent here!}
  \label{fig:topixampl}
\end{figure}

\paragraph{Assignment of Topics to Documents and Schools.} 

\PFS{Topics are initially assigned to individual documents.} We do this by
examining the document-topic distribution $p(\mathbf{z}|D) (\Theta_D)$
given by the $\Theta$-Parameter of the LDA model for each document
$D$. Therein, we could sort the topics by their probability w.r.t.\ the
document $D$. We assign a topic index to each document analogous to the
rank-1 metric \cite{evans:2014}. This metric determines a primary topic for
each document by assigning the most probable topic from the distribution
$p(\mathbf{z}|D) (\Theta_D)$ as primary topic.  This method is particularly
compelling when documents are short. Utilizing this procedure prevents
``Background''-topics, such as domain specific recurring contexts, to be
overrated in the topic statistics. We alter this approach by selecting the
two most probable topics for each document in order to preserve the
multi-topic-properties given by the LDA model. An alternative would be the
aggregation of the probability mass for each document but this will lead to
skewed statistics due to the ``Background''-topics, which have a small
probability contribution in all documents, \PFS{and hence would appear
  important in aggregation over the entire corpus.}

The next step is to aggregate of the document-wise topic index in order to
describe topical preferences of individual schools.  In the simplest case,
we compute the relative fraction $p(S,T)$ of documents from schools $S$ for
which topic $T$ in assigned as the primary or secondary topic in the sense
defined above.  Since some topics are inherently more prevalent than
others, we rather use the corresponding log-likelihood $L(S,T) = \log
p(S,T)/p(T)$, where $p(T)$ is the fraction of documents in the entire
corpus for which $T$ is important. This measure quantifies, for each
school, the emphasis given a particular topic.

\section{Phylogenetics on Topic Data} 

Each school of thought is represented by a vector of topic importances that
can be used to evaluate differences between schools. Thresholding $L(S,T)$
converts the topic importances into binary vectors that correspond to the
so-called character tables that play a central role in phylogenetics. Each
school (taxon) is the characterized by the ``presence''
(overrepresentation) or ``absence'' of a character (topic).  In this form,
the data can analyzed with maximum parsimony methods, a understood class of
computational methods from computational phylogenetics designed to infer
tree models. In principle, they are also amenable to maximum likelihood
methods; however, at this point it seems difficult to argue for specific
probabilistic transition models (but see \cite{Hruschka:15} for a fully
probabilistic model in the context of natural language
evolution). Alternatively, distances between importance vectors can be
computed. There may then be used as input to distance-based methods of tree
reconstruction. Simple distance measures that can be expected to behave
approximately additively are the sum over the absolute values of
differences of topic importance or a thresholded variant thereof. Such
distance measures also have the added value that the tree-like structure of
the data can be assessed a priori, i.e., without having to construct a
phylogenetic tree \cite{Misof:14}.

In most biological applications only taxa that are alive in the present are
observable. Even when applied to paleontological data, only leaves of the
tree are observable, while all interior nodes are only inferred. In the
case of historical records, however, true ancestor may be represented in
the data. In the case of the Daiz{\=o}ky{\=o}, as dense, dated corpus is
available that can be subdivided into time slices that then take the role
of individual taxa. These now may also represent interior nodes of the
tree. Although methods to deal with this type of phylogenetic problem are
not well developed, efficient algorithms for both distance-based and the
character-bases variants of the problem are available \cite{Telles:13} and
have been applied successfully to document data. 

\section{Concluding Remarks} 

\TODO{maybe focus here mostly on what the resouce can used for?} 

\TODO{- are there topics distinguishable due to geography or history?}

\TODO{- checking their consistency to insights from history or religious findings, and hence validating the hypothesis stated above.}


%\citelanguageresource{speecon}

\section{Bibliographical References}
\label{main:ref}

\bibliographystyle{lrec}
\bibliography{AbstractLREC}


\section{Language Resource References}
\label{lr:ref}

\TODO{all works: you need to run\\
\texttt{bibtex languageresource}\\
 in addition! NOTE: you need to remove 
\texttt{*aux} and \texttt{*bbl} files since these are used incrementally }

\bibliographystylelanguageresource{lrec}
\bibliographylanguageresource{AbstractLREC}

\end{document}
